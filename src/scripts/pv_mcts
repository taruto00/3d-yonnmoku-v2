# -*- coding: utf-8 -*-
"""pv_mcts.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VkIy_gh8ghh-mqfEj6sTB6ZiTOHXhrUu
"""

# =============================================================
# pv_mcts_bitboard.py   4×4×4 立体四目  ― ビットボード版 MCTS
# =============================================================
from pathlib import Path
from math import sqrt
import numpy as np
from tensorflow.keras.models import load_model

from game   import State,LINES76, tsumi, local_tactics_value, dr2_plane, drp_plane, ketsu_even_odd_filtered, collect_pre_threats, collect_float_pre_threats
from dual_network  import DN_INPUT_SHAPE            # (4,4,14)


# -------------------- 定数 --------------------
PV_EVALUATE_COUNT = 100 #50          # 1 盤面あたりシミュレーション数
MAX_BATCH         = 32          # たまった葉ノードがこの数を超えたらまとめて推論
SIZE  = DN_INPUT_SHAPE[0]    # 4
CHAN  = DN_INPUT_SHAPE[2]    # 14   ← ここを 9→14
DIRICHLET_ALPHA = 0.3

# -------------------------------------------------------------
# 盤面エンコード (State → (1,4,4,8))
# -------------------------------------------------------------
# pv_mcts_bitboard.py の冒頭に追加

from game import LINES76
from dual_network import DN_INPUT_SHAPE
SIZE = DN_INPUT_SHAPE[0]   # 4

def reach_bits(mine: int, yours: int) -> int:
    """
    自分（mine）があと１手で勝てるセル全体のビットマスクを返す
    """
    occ = mine | yours
    mask = 0
    for line in LINES76:  # 各４目ライン
        # 自分の石がちょうど３個 & 空マスがちょうど１箇所
        if (mine & line).bit_count() == 3 and (line & occ).bit_count() == 3:
            empties = line & ~occ
            mask |= empties
    return mask

def third_layer_indices() -> list[int]:
    """
    z == 2 （三段目）のセル idx をすべて列挙
    idx = x + y*SIZE + z*SIZE*SIZE
    """
    return [x + y*SIZE + 2*SIZE*SIZE
            for y in range(SIZE)
            for x in range(SIZE)]

def valid_floating_third(pieces: int, enemy: int) -> int:
    """
    “有効な浮き三段目決勝点” のビットマスクを返す
    ・自分があと１手で４目になるセル（reach_bits に含まれる）
    ・そのセル z==2 （third_layer_indices に含まれる）
    ・その直下(z==1) が空いている（浮いている）
    ・相手の浮き即勝点は直下にない
    """
    occ       = pieces | enemy
    my_reach  = reach_bits(pieces, enemy)
    opp_reach = reach_bits(enemy, pieces)

    valid = 0
    for idx in third_layer_indices():
        below = idx - SIZE*SIZE
        # a. 空いている
        if (occ >> idx) & 1: continue
        # b. 直下も空いている（“浮き”）
        if (occ >> below) & 1: continue
        # c. １手で４目になるセル
        if not ((my_reach >> idx) & 1): continue
        # d. 直下が相手の浮き即勝点ではない
        if (opp_reach >> below) & 1: continue

        valid |= 1 << idx
    return valid

def encode_state(state: State) -> np.ndarray:
    planes = np.zeros((SIZE, SIZE, CHAN), dtype=np.float32)

    # --- 基本 8ch ---
    mine = np.unpackbits(np.array([state.pieces], np.uint64).view(np.uint8),
                         bitorder='little').reshape(SIZE, SIZE, SIZE)
    yours = np.unpackbits(np.array([state.enemy_pieces], np.uint64).view(np.uint8),
                          bitorder='little').reshape(SIZE, SIZE, SIZE)
    planes[..., :SIZE]          = mine.transpose(1, 2, 0)   # ch 0-3
    planes[..., SIZE:2*SIZE]    = yours.transpose(1, 2, 0)  # ch 4-7

    # --- ch 8-9: DR-2 self / opp ---
    planes[..., 8] = dr2_plane(state.pieces,        state.enemy_pieces)
    planes[..., 9] = dr2_plane(state.enemy_pieces,  state.pieces)

    # --- ch 10-11: 決勝点 Even / Odd ---
    even, odd      = ketsu_even_odd_filtered(state.pieces, state.enemy_pieces)
    planes[..., 10] = even
    planes[..., 11] = odd

    # --- ch 12-13: DR-P self / opp ---
    planes[..., 12] = drp_plane(state.pieces,       state.enemy_pieces)
    planes[..., 13] = drp_plane(state.enemy_pieces, state.pieces)

    return planes[np.newaxis]      # (1,4,4,14)

# -------------------------------------------------------------
# ボルツマン分布
# -------------------------------------------------------------
def boltzmann(xs, temperature):
    xs = np.asarray(xs, dtype=np.float64)
    if temperature == 0.0:
        probs = np.zeros_like(xs); probs[np.argmax(xs)] = 1.0
        return probs
    xs = np.power(xs, 1.0/temperature)
    s = xs.sum()
    if not np.isfinite(s) or s == 0:
        return np.full_like(xs, 1.0/len(xs))
    return xs / s

# -------------------------------------------------------------
# MCTS 本体
# -------------------------------------------------------------
def pv_mcts_scores(model, state: State, temperature: float, num_simulations: int = PV_EVALUATE_COUNT, add_noise: bool = True):
    """局面 state に対して MCTS を行い，合法手確率を返す"""

    # ---- バッチ推論用バッファ ----
    leaf_states: list[np.ndarray] = []
    leaf_nodes:  list["Node"]     = []

    class Node:
        __slots__ = ("state", "p", "w", "n", "children")

        def __init__(self, state: State, p: float):
            self.state    = state
            self.p        = p          # 事前確率
            self.w        = 0.0        # 累計価値
            self.n        = 0          # 訪問回数
            self.children = None       # list[Node] | None
        # ★ここを追加 ─────────────────────
        def _update(self, value: float) -> None:
            """バックプロパゲーション用の加算ラッパ"""
            self.w += value
            self.n += 1

        # ---------- 子ノード展開 ----------
        def expand_with_nn_output(self, p_logits: np.ndarray, value: float):
            self.w += value
            self.n += 1

            legal = self.state.legal_actions()
            probs = p_logits[[idx % 16 for idx in legal]]
            s     = probs.sum()
            probs = probs / s if s else np.full_like(probs, 1.0 / len(probs))

            self.children = [Node(self.state.next_from_index(idx), float(prob))
                             for idx, prob in zip(legal, probs)]

        # ---------- 評価 ----------
        def evaluate(self) -> float:
            # 1) 終局
            if self.state.is_done():
                value =  1 if self.state.is_win()  else \
                        -1 if self.state.is_lose() else 0
                self.w += value
                self.n += 1
                return value

            # 2) ★ TSS フック ★
            #solved, v = local_tactics_value(self.state)
            #if solved:
            #    self._update(v)
            #    return v   # ここで終了 → プレイアウトしない

            # 2) 未展開：バッファに追加して仮の 0 を返す
            if self.children is None:
                # 2) ★ TSS フック ★
                solved, v = local_tactics_value(self.state)
                if solved:
                    self._update(v)
                    return v   # ここで終了 → プレイアウトしない

                leaf_states.append(encode_state(self.state))
                leaf_nodes.append(self)
                return 0.0

            # 3) 展開済み：子を選んで再帰
            value = -self.select_child().evaluate()
            self.w += value
            self.n += 1
            return value

        # ---------- 子選択 (PUCT) ----------
        def select_child(self):
            C_PUCT  = 1.0
            total_n = max(1, sum(c.n for c in self.children))
            scores = [(-c.w / c.n if c.n else 0.0) +
                      C_PUCT * c.p * sqrt(total_n) / (1 + c.n)
                      for c in self.children]
            return self.children[int(np.argmax(scores))]

    # ===== ルートノード =====
    root = Node(state, p=0.0)

    # ① ルートを NN から展開
    features = encode_state(state)
    p_logits, v0, _ = model.predict(features, batch_size=1, verbose=0)
    root.w += float(v0); root.n += 1
    root.children = [
        Node(state.next_from_index(a), float(p_logits[0][a % 16]))
        for a in state.legal_actions()
    ]

    # ② ノイズ注入（探索初手だけ）
    if add_noise:
        η = np.random.dirichlet([DIRICHLET_ALPHA] * len(root.children))
        for c, noise in zip(root.children, η):
            c.p = 0.75*c.p + 0.25*noise

    # ===== シミュレーション =====
    for sim in range(num_simulations):
        root.evaluate()

        # 葉ノードがたまったら一括推論
        if sim == 0 or len(leaf_states) >= MAX_BATCH or sim == num_simulations - 1:
            if leaf_states:
                batch = np.concatenate(leaf_states, axis=0)          # (k,4,4,8)
                p_logits, v_preds, _ = model.predict(batch,
                                                  batch_size=len(batch),
                                                  verbose=0)
                for node, logit, v in zip(leaf_nodes, p_logits, v_preds):
                    node.expand_with_nn_output(logit, float(v))

                leaf_states.clear()
                leaf_nodes.clear()

    # ===== 訪問回数 → 行動確率 =====
    visits = np.array([c.n for c in root.children], dtype=np.float32)

    probs = (np.zeros_like(visits) if temperature == 0
             else boltzmann(visits, temperature))
    if temperature == 0:
        probs[np.argmax(visits)] = 1.0

    return probs

# -------------------------------------------------------------
# 行動選択ラッパ
# -------------------------------------------------------------
def has_winning_line(bits: int) -> bool:
    # LINES76 は既に定義済み
    return any((bits & line) == line for line in LINES76)

def find_forced_action(state: State):
    mine, yours = state.pieces, state.enemy_pieces
    occ  = mine | yours

    # 自分即勝
    for idx in state.legal_actions():
        if has_winning_line(mine | (1 << idx)):
            return idx

    # 相手即勝をブロック
    for idx in state.legal_actions():
        if has_winning_line(yours | (1 << idx)):
            return idx
    return None

def pv_mcts_action(model, temperature: float = 0, num_simulations: int = PV_EVALUATE_COUNT, add_noise: bool = False):
    def act(state: State):
        # ① ルートでだけ forced block を使う
        forced = find_forced_action(state)
        if forced is not None:
            return forced

        # ② 通常の MCTS
        probs = pv_mcts_scores(model, state, temperature,
                               num_simulations, add_noise)
        return int(np.random.choice(state.legal_actions(), p=probs))
    return act
